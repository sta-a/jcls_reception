{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a430d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# 'eng' , 'ger'\n",
    "language = 'eng'\n",
    "# 'regression', 'twoclass', 'library', 'multiclass'\n",
    "task_type = 'multiclass' \n",
    "# True, False\n",
    "testing = 'True'\n",
    "\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.insert(0, '../src/')\n",
    "import os\n",
    "import pandas as pd\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import get_labels\n",
    "from cross_validation import Regression, TwoclassClassification, MulticlassClassification\n",
    "\n",
    "features_dir = f'../data/features2/{language}/'#####333333\n",
    "results_dir = f'../data/results_sentiment_test/{language}/'#333\n",
    "sentiscores_dir = '../data/sentiscores/'\n",
    "metadata_dir = '../data/metadata/'\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127ccd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get data\n",
    "'''\n",
    "textblob_labels = get_labels(language, sentiscores_dir, metadata_dir, 'textblob')\n",
    "sentiart_labels = get_labels(language, sentiscores_dir, metadata_dir, 'sentiart')\n",
    "combined_labels = get_labels(language, sentiscores_dir, metadata_dir, 'combined')\n",
    "twoclass_labels = get_labels(language, sentiscores_dir, metadata_dir, 'twoclass')\n",
    "multiclass_labels = get_labels(language, sentiscores_dir, metadata_dir, 'multiclass')\n",
    "library_labels = get_labels(language, sentiscores_dir, metadata_dir, 'library')\n",
    "#twoclass_labels['y'].plot.hist(grid=True, bins=50)\n",
    "           \n",
    "book_df = pd.read_csv(f'{features_dir}book_df.csv').rename(columns = {'book_name': 'file_name'})\n",
    "book_and_averaged_chunk_df = pd.read_csv(f'{features_dir}book_and_averaged_chunk_df.csv').rename(columns = {'book_name': 'file_name'})\n",
    "chunk_df = pd.read_csv(f'{features_dir}chunk_df.csv').rename(columns = {'book_name': 'file_name'})\n",
    "chunk_and_copied_book_df = pd.read_csv(f'{features_dir}chunk_and_copied_book_df.csv').rename(columns = {'book_name': 'file_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53596067",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All paramters\n",
    "\n",
    "models: 'svr', 'lasso', 'xgboost', 'svc'\n",
    "dimensionality_reduction: 'ss_pca_0_95', 'k_best_f_reg_0_10', 'k_best_mutual_info_0_10', None\n",
    "labels: 'textblob', 'sentiart', 'combined', 'twoclass', 'multiclass', 'library'\n",
    "'''\n",
    "model_params_dict = {'svr': [1], 'lasso': [1, 4], 'xgboost': [None], 'svc': [0.1, 1, 10, 100, 1000, 10000]} \n",
    "features_list = ['book', 'chunk', 'baac', 'cacb']\n",
    "features_dict = {'book': book_df, 'chunk': chunk_df, 'baac': book_and_averaged_chunk_df, \n",
    "                 'cacb': chunk_and_copied_book_df}\n",
    "labels_dict = {'textblob': textblob_labels, 'sentiart': sentiart_labels, 'combined': combined_labels, \n",
    "          'twoclass': twoclass_labels, 'multiclass': multiclass_labels, 'library': library_labels}\n",
    "drop_columns_list = [\n",
    "    ['average_sentence_embedding', 'doc2vec_chunk_embedding'],\n",
    "    ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos']]\n",
    "if language == 'eng':\n",
    "    drop_columns_list.extend([\n",
    "        ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->'], \n",
    "        ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos']])\n",
    "    \n",
    "# Model-specific column names for writing results to file\n",
    "general_cols = ['language', 'task_type', 'model', 'model_param', 'labels_string', 'features_string',\n",
    "    'dimensionality_reduction', 'drop_columns']\n",
    "regression_cols = general_cols + ['mean_train_mse', 'mean_train_rmse', 'mean_train_mae', 'mean_train_r2', \n",
    "    'mean_train_corr', 'mean_validation_mse', 'mean_validation_rmse', 'mean_validation_mae', \n",
    "    'mean_validation_r2', 'mean_validation_corr', 'mean_p_value']\n",
    "twoclass_cols = general_cols + ['mean_train_acc', 'mean_train_balanced_acc', 'mean_validation_acc', 'mean_validation_balanced_acc'] # also used for library\n",
    "multiclass_cols = general_cols + ['mean_train_f1', 'mean_validation_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Link parameters to models\n",
    "'''\n",
    "regression_dict = {\n",
    "    'model': ['xgboost'], \n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': features_list,\n",
    "    'labels': ['textblob', 'sentiart', 'combined'],\n",
    "    'drop_columns': drop_columns_list,\n",
    "    'model_cols': regression_cols}\n",
    "twoclass_dict = {\n",
    "    'model': ['svc', 'xgboost'], \n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': ['book', 'baac'],\n",
    "    'labels': ['twoclass'],\n",
    "    'drop_columns': drop_columns_list,\n",
    "    'model_cols': twoclass_cols}\n",
    "library_dict = deepcopy(twoclass_dict)\n",
    "library_dict['labels'] = ['library']\n",
    "multiclass_dict = {\n",
    "    'model': ['svc', 'xgboost'], \n",
    "    'dimensionality_reduction': [None],\n",
    "    'features': ['book', 'baac'],\n",
    "    'labels': ['multiclass'],\n",
    "    'drop_columns': drop_columns_list,\n",
    "    'model_cols': multiclass_cols}\n",
    "\n",
    "# Test CV with only one paramter combination\n",
    "testing_reg_dict = {\n",
    "    'model': ['xgboost'], \n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': ['book'],\n",
    "    'labels': ['combined'],\n",
    "    'drop_columns': [drop_columns_list[-1]],\n",
    "    'model_cols': regression_cols}\n",
    "testing_twoclass_dict = {\n",
    "    'model': ['xgboost', 'svc'], #xgboost\n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': ['book'], #'baac'\n",
    "    'labels': ['twoclass'],\n",
    "    'drop_columns': [drop_columns_list[-1]],\n",
    "    'model_cols': twoclass_cols}\n",
    "testing_library_dict = deepcopy(testing_twoclass_dict)\n",
    "testing_library_dict['labels'] = ['library']\n",
    "testing_multiclass_dict = {\n",
    "    'model': ['xgboost', 'svc'], #xgboost\n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': ['book'], #'baac'\n",
    "    'labels': ['multiclass'],\n",
    "    'drop_columns': [drop_columns_list[-1]],\n",
    "    'model_cols': multiclass_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2911327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run Cross-Validation\n",
    "'''  \n",
    "if task_type == 'regression':\n",
    "    param_dict = regression_dict\n",
    "elif task_type == 'library':\n",
    "    param_dict = library_dict\n",
    "elif task_type == 'twoclass':\n",
    "    param_dict = twoclass_dict\n",
    "elif task_type == 'multiclass':\n",
    "    param_dict = multiclass_dict\n",
    "\n",
    "##Overwrite for testing \n",
    "if testing == 'True':\n",
    "    if task_type == 'regression':\n",
    "        param_dict = testing_reg_dict\n",
    "    if task_type == 'twoclass':\n",
    "        param_dict = testing_twoclass_dict\n",
    "    elif task_type == 'multiclass':\n",
    "        param_dict = testing_multiclass_dict\n",
    "    elif task_type == 'library':\n",
    "        param_dict = testing_library_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3addad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "Fold: 1, TrainF1: 0.868, ValF1: 0.416\n",
      "Fold: 2, TrainF1: 0.537, ValF1: 0.385\n",
      "Fold: 3, TrainF1: 0.997, ValF1: 0.261\n",
      "Fold: 4, TrainF1: 0.849, ValF1: 0.307\n",
      "Fold: 5, TrainF1: 0.891, ValF1: 0.275\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        245   15   46   59  365\n",
      "1.0          3    2    5    5   15\n",
      "2.0         18    7   15   23   63\n",
      "3.0         40    7   32   34  113\n",
      "All        306   31   98  121  556 \n",
      "--------------------------\n",
      "TrainF1: 0.828, ValidationF1: 0.329\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "eng multiclass xgboost None multiclass book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.828, 0.329]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dropped 0 columns.\n",
      "Fold: 1, TrainF1: 0.296, ValF1: 0.338\n",
      "Fold: 2, TrainF1: 0.241, ValF1: 0.281\n",
      "Fold: 3, TrainF1: 0.353, ValF1: 0.204\n",
      "Fold: 4, TrainF1: 0.294, ValF1: 0.251\n",
      "Fold: 5, TrainF1: 0.297, ValF1: 0.224\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        227   70   31   37  365\n",
      "1.0          2    4    6    3   15\n",
      "2.0          8   34   11   10   63\n",
      "3.0         26   47   21   19  113\n",
      "All        263  155   69   69  556 \n",
      "--------------------------\n",
      "TrainF1: 0.296, ValidationF1: 0.259\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "eng multiclass svc 0.1 multiclass book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.296, 0.259]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dropped 0 columns.\n",
      "Fold: 1, TrainF1: 0.307, ValF1: 0.316\n",
      "Fold: 2, TrainF1: 0.258, ValF1: 0.293\n",
      "Fold: 3, TrainF1: 0.349, ValF1: 0.194\n",
      "Fold: 4, TrainF1: 0.335, ValF1: 0.292\n",
      "Fold: 5, TrainF1: 0.286, ValF1: 0.234\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        204   61   66   34  365\n",
      "1.0          2    2    8    3   15\n",
      "2.0          5   20   26   12   63\n",
      "3.0         16   39   42   16  113\n",
      "All        227  122  142   65  556 \n",
      "--------------------------\n",
      "TrainF1: 0.307, ValidationF1: 0.266\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "eng multiclass svc 1 multiclass book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.307, 0.266]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dropped 0 columns.\n",
      "Fold: 1, TrainF1: 0.334, ValF1: 0.408\n",
      "Fold: 2, TrainF1: 0.322, ValF1: 0.358\n",
      "Fold: 3, TrainF1: 0.334, ValF1: 0.204\n",
      "Fold: 4, TrainF1: 0.342, ValF1: 0.383\n",
      "Fold: 5, TrainF1: 0.301, ValF1: 0.267\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        202   52   72   39  365\n",
      "1.0          2    2    8    3   15\n",
      "2.0          4   17   31   11   63\n",
      "3.0         12   39   36   26  113\n",
      "All        220  110  147   79  556 \n",
      "--------------------------\n",
      "TrainF1: 0.327, ValidationF1: 0.324\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "eng multiclass svc 10 multiclass book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.327, 0.324]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dropped 0 columns.\n",
      "Fold: 1, TrainF1: 0.344, ValF1: 0.344\n",
      "Fold: 2, TrainF1: 0.326, ValF1: 0.396\n",
      "Fold: 3, TrainF1: 0.333, ValF1: 0.197\n",
      "Fold: 4, TrainF1: 0.352, ValF1: 0.394\n",
      "Fold: 5, TrainF1: 0.297, ValF1: 0.268\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        196   61   60   48  365\n",
      "1.0          2    4    5    4   15\n",
      "2.0          3   26   23   11   63\n",
      "3.0         10   41   32   30  113\n",
      "All        211  132  120   93  556 \n",
      "--------------------------\n",
      "TrainF1: 0.331, ValidationF1: 0.32\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "eng multiclass svc 100 multiclass book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.331, 0.32]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dropped 0 columns.\n",
      "Fold: 1, TrainF1: 0.369, ValF1: 0.396\n",
      "Fold: 2, TrainF1: 0.337, ValF1: 0.437\n",
      "Fold: 3, TrainF1: 0.366, ValF1: 0.25\n",
      "Fold: 4, TrainF1: 0.351, ValF1: 0.313\n",
      "Fold: 5, TrainF1: 0.307, ValF1: 0.241\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        192   58   59   56  365\n",
      "1.0          2    3    4    6   15\n",
      "2.0          4   18   27   14   63\n",
      "3.0         11   36   30   36  113\n",
      "All        209  115  120  112  556 \n",
      "--------------------------\n",
      "TrainF1: 0.346, ValidationF1: 0.327\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "eng multiclass svc 1000 multiclass book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.346, 0.327]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dropped 0 columns.\n",
      "Fold: 1, TrainF1: 0.325, ValF1: 0.31\n",
      "Fold: 2, TrainF1: 0.348, ValF1: 0.435\n",
      "Fold: 3, TrainF1: 0.366, ValF1: 0.255\n",
      "Fold: 4, TrainF1: 0.354, ValF1: 0.337\n",
      "Fold: 5, TrainF1: 0.324, ValF1: 0.271\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        188   65   61   51  365\n",
      "1.0          2    5    4    4   15\n",
      "2.0          1   27   23   12   63\n",
      "3.0         10   36   33   34  113\n",
      "All        201  133  121  101  556 \n",
      "--------------------------\n",
      "TrainF1: 0.343, ValidationF1: 0.322\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "eng multiclass svc 10000 multiclass book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.343, 0.322]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with open(f'{results_dir}results-{language}-{task_type}-log.csv', 'a') as f:\n",
    "    f.write('\\t'.join(param_dict['model_cols']) + '\\n')\n",
    "for model in param_dict['model']:\n",
    "    model_param = model_params_dict[model]\n",
    "    for model_param in model_param:\n",
    "        for labels_string in param_dict['labels']:\n",
    "            labels = deepcopy(labels_dict[labels_string])\n",
    "            for features_string in param_dict['features']:\n",
    "                df = deepcopy(features_dict[features_string])\n",
    "                for dimensionality_reduction in param_dict['dimensionality_reduction']:\n",
    "                    for drop_columns in param_dict['drop_columns']:\n",
    "                        if task_type == 'regression':\n",
    "                            experiment = Regression(\n",
    "                                results_dir=results_dir,\n",
    "                                language=language,\n",
    "                                task_type=task_type,\n",
    "                                model=model,\n",
    "                                model_param=model_param,\n",
    "                                labels_string=labels_string,\n",
    "                                labels=labels,\n",
    "                                features_string=features_string,\n",
    "                                df=df,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                drop_columns=drop_columns,\n",
    "                                verbose=True)\n",
    "                        elif (task_type == 'twoclass') or (task_type == 'library'):\n",
    "                            experiment = TwoclassClassification(\n",
    "                                results_dir=results_dir,\n",
    "                                language=language,\n",
    "                                task_type=task_type,\n",
    "                                model=model,\n",
    "                                model_param=model_param,\n",
    "                                labels_string=labels_string,\n",
    "                                labels=labels,\n",
    "                                features_string=features_string,\n",
    "                                df=df,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                drop_columns=drop_columns,\n",
    "                                verbose=True)\n",
    "\n",
    "                        elif task_type == 'multiclass':\n",
    "                            experiment = MulticlassClassification(\n",
    "                                results_dir=results_dir,\n",
    "                                language=language,\n",
    "                                task_type=task_type,\n",
    "                                model=model,\n",
    "                                model_param=model_param,\n",
    "                                labels_string=labels_string,\n",
    "                                labels=labels,\n",
    "                                features_string=features_string,\n",
    "                                df=df,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                drop_columns=drop_columns,\n",
    "                                verbose=True)\n",
    "\n",
    "                        returned_values = experiment.run()\n",
    "                        all_columns = [language, task_type, model, model_param, labels_string, features_string,\n",
    "                                       dimensionality_reduction, drop_columns] + returned_values\n",
    "                        \n",
    "                        with open(f'{results_dir}results-{language}-{task_type}-log.csv', 'a') as f:\n",
    "                            f.write('\\t'.join([str(x) for x in all_columns]) + '\\n')\n",
    "                            results.append(all_columns) \n",
    "\n",
    "                        print(language, task_type, model, model_param, labels_string, features_string,\n",
    "                                dimensionality_reduction, drop_columns, returned_values)\n",
    "                        print('\\n-----------------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=param_dict['model_cols'])\n",
    "#results_df.to_csv(f'{results_dir}results-{language}-{task_type}-final.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d9a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6bd172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd98959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362d91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74664f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f8a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
