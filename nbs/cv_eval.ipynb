{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# 'eng' , 'ger'\n",
    "language = 'eng'\n",
    "# 'regression', 'twoclass', 'library', 'multiclass'\n",
    "task_type = 'multiclass' \n",
    "# True, False\n",
    "testing = 'True'\n",
    "\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.insert(0, '../src/')\n",
    "import os\n",
    "import pandas as pd\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import get_labels\n",
    "from cross_validation import Regression, TwoclassClassification, MulticlassClassification\n",
    "\n",
    "features_dir = f'../data/features/{language}/'\n",
    "results_dir = f'../data/results_sentiment/{language}/'\n",
    "sentiscores_dir = '../data/sentiscores/'\n",
    "metadata_dir = '../data/metadata/'\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ccd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get data\n",
    "'''\n",
    "textblob_labels = get_labels(language, sentiscores_dir, metadata_dir, 'textblob')\n",
    "sentiart_labels = get_labels(language, sentiscores_dir, metadata_dir, 'sentiart')\n",
    "combined_labels = get_labels(language, sentiscores_dir, metadata_dir, 'combined')\n",
    "twoclass_labels = get_labels(language, sentiscores_dir, metadata_dir, 'twoclass')\n",
    "multiclass_labels = get_labels(language, sentiscores_dir, metadata_dir, 'multiclass')\n",
    "library_labels = get_labels(language, sentiscores_dir, metadata_dir, 'library')\n",
    "#twoclass_labels['y'].plot.hist(grid=True, bins=50)\n",
    "           \n",
    "book_df = pd.read_csv(f'{features_dir}book_df.csv').rename(columns = {'book_name': 'file_name'})\n",
    "book_and_averaged_chunk_df = pd.read_csv(f'{features_dir}book_and_averaged_chunk_df.csv').rename(columns = {'book_name': 'file_name'})\n",
    "chunk_df = pd.read_csv(f'{features_dir}chunk_df.csv').rename(columns = {'book_name': 'file_name'})\n",
    "chunk_and_copied_book_df = pd.read_csv(f'{features_dir}chunk_and_copied_book_df.csv').rename(columns = {'book_name': 'file_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All paramters\n",
    "\n",
    "models: 'svr', 'lasso', 'xgboost', 'svc'\n",
    "dimensionality_reduction: 'ss_pca_0_95', 'k_best_f_reg_0_10', 'k_best_mutual_info_0_10', None\n",
    "labels: 'textblob', 'sentiart', 'combined', 'twoclass', 'multiclass', 'library'\n",
    "'''\n",
    "model_params_dict = {'svr': [1], 'lasso': [1, 4], 'xgboost': [None], 'svc': [0.1, 1, 10, 100, 1000, 10000]} \n",
    "features_list = ['book', 'chunk', 'baac', 'cacb']\n",
    "features_dict = {'book': book_df, 'chunk': chunk_df, 'baac': book_and_averaged_chunk_df, \n",
    "                 'cacb': chunk_and_copied_book_df}\n",
    "labels_dict = {'textblob': textblob_labels, 'sentiart': sentiart_labels, 'combined': combined_labels, \n",
    "          'twoclass': twoclass_labels, 'multiclass': multiclass_labels, 'library': library_labels}\n",
    "drop_columns_list = [\n",
    "    ['average_sentence_embedding', 'doc2vec_chunk_embedding'],\n",
    "    ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos']]\n",
    "if language == 'eng':\n",
    "    drop_columns_list.extend([\n",
    "        ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->'], \n",
    "        ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos']])\n",
    "    \n",
    "# Model-specific column names for writing results to file\n",
    "general_cols = ['language', 'task_type', 'model', 'model_param', 'labels_string', 'features_string',\n",
    "    'dimensionality_reduction', 'drop_columns']\n",
    "regression_cols = general_cols + ['mean_train_mse', 'mean_train_rmse', 'mean_train_mae', 'mean_train_r2', \n",
    "    'mean_train_corr', 'mean_validation_mse', 'mean_validation_rmse', 'mean_validation_mae', \n",
    "    'mean_validation_r2', 'mean_validation_corr', 'mean_p_value']\n",
    "twoclass_cols = general_cols + ['mean_train_acc', 'mean_train_balanced_acc', 'mean_validation_acc', 'mean_validation_balanced_acc'] # also used for library\n",
    "multiclass_cols = general_cols + ['mean_train_f1', 'mean_validation_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Link parameters to models\n",
    "'''\n",
    "regression_dict = {\n",
    "    'model': ['xgboost'], \n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': features_list,\n",
    "    'labels': ['textblob', 'sentiart', 'combined'],\n",
    "    'drop_columns': drop_columns_list,\n",
    "    'model_cols': regression_cols}\n",
    "twoclass_dict = {\n",
    "    'model': ['svc', 'xgboost'], \n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': ['book', 'baac'],\n",
    "    'labels': ['twoclass'],\n",
    "    'drop_columns': drop_columns_list,\n",
    "    'model_cols': twoclass_cols}\n",
    "library_dict = deepcopy(twoclass_dict)\n",
    "library_dict['labels'] = ['library']\n",
    "multiclass_dict = {\n",
    "    'model': ['svc', 'xgboost'], \n",
    "    'dimensionality_reduction': [None],\n",
    "    'features': ['book', 'baac'],\n",
    "    'labels': ['multiclass'],\n",
    "    'drop_columns': drop_columns_list,\n",
    "    'model_cols': multiclass_cols}\n",
    "\n",
    "# Test CV with only one paramter combination\n",
    "testing_reg_dict = {\n",
    "    'model': ['xgboost'], \n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': ['book'],\n",
    "    'labels': ['combined'],\n",
    "    'drop_columns': [drop_columns_list[-1]],\n",
    "    'model_cols': regression_cols}\n",
    "testing_twoclass_dict = {\n",
    "    'model': ['xgboost', 'svc'], #xgboost\n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': ['book'], #'baac'\n",
    "    'labels': ['twoclass'],\n",
    "    'drop_columns': [drop_columns_list[-1]],\n",
    "    'model_cols': twoclass_cols}\n",
    "testing_library_dict = deepcopy(testing_twoclass_dict)\n",
    "testing_library_dict['labels'] = ['library']\n",
    "testing_multiclass_dict = {\n",
    "    'model': ['xgboost', 'svc'], #xgboost\n",
    "    'dimensionality_reduction': [None], \n",
    "    'features': ['book'], #'baac'\n",
    "    'labels': ['multiclass'],\n",
    "    'drop_columns': [drop_columns_list[-1]],\n",
    "    'model_cols': multiclass_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2911327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run Cross-Validation\n",
    "'''  \n",
    "if task_type == 'regression':\n",
    "    param_dict = regression_dict\n",
    "elif task_type == 'library':\n",
    "    param_dict = library_dict\n",
    "elif task_type == 'twoclass':\n",
    "    param_dict = twoclass_dict\n",
    "elif task_type == 'multiclass':\n",
    "    param_dict = multiclass_dict\n",
    "\n",
    "##Overwrite for testing \n",
    "if testing == 'True':\n",
    "    if task_type == 'regression':\n",
    "        param_dict = testing_reg_dict\n",
    "    if task_type == 'twoclass':\n",
    "        param_dict = testing_twoclass_dict\n",
    "    elif task_type == 'multiclass':\n",
    "        param_dict = testing_multiclass_dict\n",
    "    elif task_type == 'library':\n",
    "        param_dict = testing_library_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3addad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open(f'{results_dir}results-{language}-{task_type}-log.csv', 'a') as f:\n",
    "    f.write('\\t'.join(param_dict['model_cols']) + '\\n')\n",
    "for model in param_dict['model']:\n",
    "    model_param = model_params_dict[model]\n",
    "    for model_param in model_param:\n",
    "        for labels_string in param_dict['labels']:\n",
    "            labels = deepcopy(labels_dict[labels_string])\n",
    "            for features_string in param_dict['features']:\n",
    "                df = deepcopy(features_dict[features_string])\n",
    "                for dimensionality_reduction in param_dict['dimensionality_reduction']:\n",
    "                    for drop_columns in param_dict['drop_columns']:\n",
    "                        if task_type == 'regression':\n",
    "                            experiment = Regression(\n",
    "                                results_dir=results_dir,\n",
    "                                language=language,\n",
    "                                task_type=task_type,\n",
    "                                model=model,\n",
    "                                model_param=model_param,\n",
    "                                labels_string=labels_string,\n",
    "                                labels=labels,\n",
    "                                features_string=features_string,\n",
    "                                df=df,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                drop_columns=drop_columns,\n",
    "                                verbose=True)\n",
    "                        elif (task_type == 'twoclass') or (task_type == 'library'):\n",
    "                            experiment = TwoclassClassification(\n",
    "                                results_dir=results_dir,\n",
    "                                language=language,\n",
    "                                task_type=task_type,\n",
    "                                model=model,\n",
    "                                model_param=model_param,\n",
    "                                labels_string=labels_string,\n",
    "                                labels=labels,\n",
    "                                features_string=features_string,\n",
    "                                df=df,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                drop_columns=drop_columns,\n",
    "                                verbose=True)\n",
    "\n",
    "                        elif task_type == 'multiclass':\n",
    "                            experiment = MulticlassClassification(\n",
    "                                results_dir=results_dir,\n",
    "                                language=language,\n",
    "                                task_type=task_type,\n",
    "                                model=model,\n",
    "                                model_param=model_param,\n",
    "                                labels_string=labels_string,\n",
    "                                labels=labels,\n",
    "                                features_string=features_string,\n",
    "                                df=df,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                drop_columns=drop_columns,\n",
    "                                verbose=True)\n",
    "\n",
    "                        returned_values = experiment.run()\n",
    "                        all_columns = [language, task_type, model, model_param, labels_string, features_string,\n",
    "                                       dimensionality_reduction, drop_columns] + returned_values\n",
    "                        \n",
    "                        with open(f'{results_dir}results-{language}-{task_type}-log.csv', 'a') as f:\n",
    "                            f.write('\\t'.join([str(x) for x in all_columns]) + '\\n')\n",
    "                            results.append(all_columns) \n",
    "\n",
    "                        print(language, task_type, model, model_param, labels_string, features_string,\n",
    "                                dimensionality_reduction, drop_columns, returned_values)\n",
    "                        print('\\n-----------------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=param_dict['model_cols'])\n",
    "#results_df.to_csv(f'{results_dir}results-{language}-{task_type}-final.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d9a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6bd172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd98959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362d91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74664f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f8a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
